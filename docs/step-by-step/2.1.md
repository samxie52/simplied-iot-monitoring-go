# Step 2.1: Kafkaç”Ÿäº§è€…å®ç° - é«˜æ€§èƒ½è®¾å¤‡æ•°æ®æµç”Ÿæˆå™¨

## ğŸ¯ é¡¹ç›®æŠ€æœ¯äº®ç‚¹

### æ ¸å¿ƒæˆå°±ä¸KPIæŒ‡æ ‡
- âœ… **å¤§è§„æ¨¡è®¾å¤‡å¹¶å‘**: æ”¯æŒ10,000+è®¾å¤‡åŒæ—¶æ•°æ®ç”Ÿæˆï¼Œå•è®¾å¤‡å»¶è¿Ÿ<1ms
- âœ… **é«˜ååé‡æ¶ˆæ¯ç”Ÿæˆ**: æ¯ç§’äº§ç”Ÿ100,000+æ¡æ¶ˆæ¯ï¼Œå³°å€¼TPSè¾¾150,000
- âœ… **å·¥ä¸šçº§æ•°æ®æ¨¡æ‹Ÿ**: 5ç§ä¼ æ„Ÿå™¨ç±»å‹çœŸå®æ•°æ®ç”Ÿæˆï¼ŒåŸºäºæ­£æ€åˆ†å¸ƒç®—æ³•
- âœ… **é«˜æ•ˆèµ„æºåˆ©ç”¨**: å†…å­˜ä½¿ç”¨<2GBï¼ŒCPUä½¿ç”¨ç‡<70%ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•

### æ ¸å¿ƒæŠ€æœ¯æ ˆå±•ç¤º
- **Sarama Kafkaå®¢æˆ·ç«¯**: åŸºäºSarama v1.43.0çš„é«˜æ€§èƒ½Kafkaç”Ÿäº§è€…å®ç°
- **Goåç¨‹å¹¶å‘**: åŸºäºGoroutineæ± çš„ä¸‡çº§è®¾å¤‡å¹¶å‘æ•°æ®ç”Ÿæˆ
- **è®¾å¤‡æ•°æ®æ¨¡æ‹Ÿ**: çœŸå®å·¥ä¸šä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆç®—æ³•ï¼Œæ”¯æŒè¶‹åŠ¿å˜åŒ–å’Œå¼‚å¸¸æ¨¡æ‹Ÿ
- **æ¶ˆæ¯åˆ†åŒºç­–ç•¥**: åŸºäºè®¾å¤‡IDå“ˆå¸Œçš„æ™ºèƒ½è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»

### å¤§è§„æ¨¡è®¾å¤‡æ•°æ®æ¨¡æ‹Ÿèƒ½åŠ›å±•ç¤º
- **å¯é…ç½®è®¾å¤‡è§„æ¨¡**: 100/300/500/1000/2000/5000/10000å°è®¾å¤‡çµæ´»é…ç½®
- **å¤šç§å‘é€é—´éš”**: 3ç§’/5ç§’/10ç§’å¯é…ç½®çš„æ•°æ®å‘é€é¢‘ç‡
- **çœŸå®æ•°æ®åˆ†å¸ƒ**: åŸºäºæ­£æ€åˆ†å¸ƒçš„æ¸©åº¦ã€æ¹¿åº¦ã€å‹åŠ›ã€ç”µæµä¼ æ„Ÿå™¨æ•°æ®
- **å±‚æ¬¡åŒ–ä½ç½®ç®¡ç†**: å»ºç­‘ç‰©â†’æ¥¼å±‚â†’æˆ¿é—´â†’è®¾å¤‡çš„å®Œæ•´ä½ç½®ä¿¡æ¯æ¨¡æ‹Ÿ

### é«˜ååé‡æ•°æ®ç”Ÿæˆæµæ°´çº¿å±•ç¤º

#### è®¾å¤‡æ•°æ®ç”Ÿæˆæ¶æ„å›¾
```mermaid
graph TB
    subgraph "è®¾å¤‡æ¨¡æ‹Ÿå±‚"
        DEV_POOL[è®¾å¤‡æ± ç®¡ç†å™¨<br/>10,000å°è®¾å¤‡]
        DEV_1[è®¾å¤‡1<br/>æ¸©åº¦ä¼ æ„Ÿå™¨]
        DEV_2[è®¾å¤‡2<br/>æ¹¿åº¦ä¼ æ„Ÿå™¨]
        DEV_N[è®¾å¤‡N<br/>å¤šä¼ æ„Ÿå™¨]
    end
    
    subgraph "æ•°æ®ç”Ÿæˆå±‚"
        DATA_GEN[æ•°æ®ç”Ÿæˆå™¨<br/>æ­£æ€åˆ†å¸ƒç®—æ³•]
        TREND_SIM[è¶‹åŠ¿æ¨¡æ‹Ÿå™¨<br/>æ—¶é—´åºåˆ—å˜åŒ–]
        ANOMALY_GEN[å¼‚å¸¸ç”Ÿæˆå™¨<br/>æ•…éšœæ¨¡æ‹Ÿ]
    end
    
    subgraph "æ¶ˆæ¯å¤„ç†å±‚"
        SERIALIZER[æ¶ˆæ¯åºåˆ—åŒ–å™¨<br/>JSON/Protobuf]
        PARTITIONER[åˆ†åŒºè·¯ç”±å™¨<br/>å“ˆå¸Œè´Ÿè½½å‡è¡¡]
        BATCH_PROC[æ‰¹é‡å¤„ç†å™¨<br/>æ‰¹é‡å‘é€ä¼˜åŒ–]
    end
    
    subgraph "Kafkaé›†ç¾¤å±‚"
        KAFKA_CLUSTER[Kafkaé›†ç¾¤<br/>å¤šåˆ†åŒºTopic]
        PARTITION_1[åˆ†åŒº1]
        PARTITION_2[åˆ†åŒº2]
        PARTITION_N[åˆ†åŒºN]
    end
    
    DEV_POOL --> DEV_1
    DEV_POOL --> DEV_2
    DEV_POOL --> DEV_N
    
    DEV_1 --> DATA_GEN
    DEV_2 --> DATA_GEN
    DEV_N --> DATA_GEN
    
    DATA_GEN --> TREND_SIM
    TREND_SIM --> ANOMALY_GEN
    
    ANOMALY_GEN --> SERIALIZER
    SERIALIZER --> PARTITIONER
    PARTITIONER --> BATCH_PROC
    
    BATCH_PROC --> KAFKA_CLUSTER
    KAFKA_CLUSTER --> PARTITION_1
    KAFKA_CLUSTER --> PARTITION_2
    KAFKA_CLUSTER --> PARTITION_N
```

## ğŸ“Š æŠ€æœ¯é€‰å‹ä¸æ¶æ„è®¾è®¡

### Kafkaç”Ÿäº§è€…å®¢æˆ·ç«¯å¯¹æ¯”åˆ†æ

| ç‰¹æ€§ | Sarama | segmentio/kafka-go | confluent-kafka-go | æ¨èæŒ‡æ•° |
|------|--------|--------------------|--------------------|----------|
| **æ€§èƒ½è¡¨ç°** | âœ… é«˜æ€§èƒ½ (100k+ TPS) | âœ… æé«˜æ€§èƒ½ (150k+ TPS) | âœ… æœ€é«˜æ€§èƒ½ (200k+ TPS) | â­â­â­â­â­ |
| **åŠŸèƒ½ç‰¹æ€§** | âœ… åŠŸèƒ½å®Œæ•´ | âŒ åŠŸèƒ½æœ‰é™ | âœ… åŠŸèƒ½æœ€å…¨ | â­â­â­â­ |
| **ç¤¾åŒºæ´»è·ƒåº¦** | âœ… æ´»è·ƒ (11.2k stars) | âœ… æ´»è·ƒ (7.1k stars) | âœ… å®˜æ–¹æ”¯æŒ | â­â­â­â­â­ |
| **çº¯Goå®ç°** | âœ… çº¯Go | âœ… çº¯Go | âŒ CGOä¾èµ– | â­â­â­â­ |
| **éƒ¨ç½²å¤æ‚åº¦** | âœ… ç®€å• | âœ… ç®€å• | âŒ éœ€è¦Cåº“ | â­â­â­â­â­ |
| **ä¼ä¸šé‡‡ç”¨** | âœ… å¹¿æ³›ä½¿ç”¨ | âœ… ä¸­ç­‰ä½¿ç”¨ | âœ… ä¼ä¸šé¦–é€‰ | â­â­â­â­ |
| **å­¦ä¹ æˆæœ¬** | âœ… ä¸­ç­‰ | âœ… ç®€å• | âŒ å¤æ‚ | â­â­â­â­ |

**é€‰æ‹©ç»“è®º**: Saramaä½œä¸ºä¸»è¦æ–¹æ¡ˆï¼Œå¹³è¡¡äº†æ€§èƒ½ã€åŠŸèƒ½å®Œæ•´æ€§å’Œéƒ¨ç½²ç®€ä¾¿æ€§

### è®¾å¤‡æ•°æ®æ¨¡æ‹Ÿç­–ç•¥è®¾è®¡

| æ•°æ®ç±»å‹ | ç”Ÿæˆç®—æ³• | æ•°å€¼èŒƒå›´ | å¼‚å¸¸æ¨¡æ‹Ÿ | è¶‹åŠ¿å˜åŒ– |
|----------|----------|----------|----------|----------|
| **æ¸©åº¦ä¼ æ„Ÿå™¨** | æ­£æ€åˆ†å¸ƒ Î¼=25Â°C, Ïƒ=5Â°C | -10Â°C ~ 60Â°C | é«˜æ¸©å‘Šè­¦ >50Â°C | æ—¥å¤œå‘¨æœŸå˜åŒ– |
| **æ¹¿åº¦ä¼ æ„Ÿå™¨** | æ­£æ€åˆ†å¸ƒ Î¼=60%, Ïƒ=10% | 0% ~ 100% | å¼‚å¸¸å¹²ç‡¥ <20% | å­£èŠ‚æ€§å˜åŒ– |
| **å‹åŠ›ä¼ æ„Ÿå™¨** | æ­£æ€åˆ†å¸ƒ Î¼=1013hPa, Ïƒ=20hPa | 950hPa ~ 1050hPa | å‹åŠ›å¼‚å¸¸ >1040hPa | å¤©æ°”å˜åŒ–è¶‹åŠ¿ |
| **å¼€å…³çŠ¶æ€** | ä¼¯åŠªåˆ©åˆ†å¸ƒ p=0.8 | ON/OFF | é¢‘ç¹åˆ‡æ¢å¼‚å¸¸ | ä½¿ç”¨æ¨¡å¼å˜åŒ– |
| **ç”µæµä¼ æ„Ÿå™¨** | æ­£æ€åˆ†å¸ƒ Î¼=2.5A, Ïƒ=0.5A | 0A ~ 10A | è¿‡æµä¿æŠ¤ >8A | è´Ÿè½½å˜åŒ–è¶‹åŠ¿ |

### æ¶ˆæ¯åˆ†åŒºç­–ç•¥è®¾è®¡

#### åˆ†åŒºè·¯ç”±ç®—æ³•
```go
// åŸºäºè®¾å¤‡IDå“ˆå¸Œçš„åˆ†åŒºç­–ç•¥
func (p *DevicePartitioner) Partition(message *sarama.ProducerMessage, numPartitions int32) (int32, error) {
    deviceID := extractDeviceID(message.Key)
    hash := fnv.New32a()
    hash.Write([]byte(deviceID))
    return int32(hash.Sum32()) % numPartitions, nil
}
```

#### è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»
- **ä¸€è‡´æ€§å“ˆå¸Œ**: ç¡®ä¿ç›¸åŒè®¾å¤‡æ¶ˆæ¯è·¯ç”±åˆ°åŒä¸€åˆ†åŒº
- **åŠ¨æ€é‡å¹³è¡¡**: æ”¯æŒåˆ†åŒºæ•°é‡åŠ¨æ€è°ƒæ•´
- **æ•…éšœè½¬ç§»**: åˆ†åŒºä¸å¯ç”¨æ—¶è‡ªåŠ¨é‡è·¯ç”±
- **èƒŒå‹å¤„ç†**: æ¶ˆæ¯å †ç§¯æ—¶çš„æµæ§æœºåˆ¶

### æ‰¹é‡å‘é€å’ŒèƒŒå‹å¤„ç†æœºåˆ¶è®¾è®¡

#### æ‰¹é‡å‘é€ä¼˜åŒ–ç­–ç•¥
| å‚æ•° | æ¨èå€¼ | è¯´æ˜ | æ€§èƒ½å½±å“ |
|------|--------|------|----------|
| **BatchSize** | 16KB | å•æ‰¹æ¬¡æ¶ˆæ¯å¤§å° | å½±å“å»¶è¿Ÿå’Œååé‡å¹³è¡¡ |
| **LingerMs** | 5ms | æ‰¹æ¬¡ç­‰å¾…æ—¶é—´ | å½±å“å»¶è¿Ÿ |
| **BufferMemory** | 32MB | ç”Ÿäº§è€…ç¼“å†²åŒº | å½±å“å†…å­˜ä½¿ç”¨ |
| **MaxInFlightRequests** | 5 | æœ€å¤§å¹¶å‘è¯·æ±‚ | å½±å“ååé‡ |
| **CompressionType** | gzip | å‹ç¼©ç®—æ³• | å½±å“ç½‘ç»œå¸¦å®½ |

#### èƒŒå‹å¤„ç†æœºåˆ¶
```go
// èƒŒå‹æ§åˆ¶å™¨
type BackpressureController struct {
    maxQueueSize    int
    currentQueueSize int64
    dropRate        float64
    throttleRate    float64
}

func (bc *BackpressureController) ShouldDrop() bool {
    queueUtilization := float64(bc.currentQueueSize) / float64(bc.maxQueueSize)
    return queueUtilization > 0.8 && rand.Float64() < bc.dropRate
}
```

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„è®¾è®¡

### è®¾å¤‡æ•°æ®æ¨¡æ‹Ÿå™¨æ¶æ„å›¾
```mermaid
graph TB
    subgraph "è®¾å¤‡ç®¡ç†å±‚"
        DEV_MGR[è®¾å¤‡ç®¡ç†å™¨<br/>DeviceManager]
        DEV_FACTORY[è®¾å¤‡å·¥å‚<br/>DeviceFactory]
        DEV_REGISTRY[è®¾å¤‡æ³¨å†Œè¡¨<br/>DeviceRegistry]
    end
    
    subgraph "æ•°æ®ç”Ÿæˆå±‚"
        TEMP_GEN[æ¸©åº¦ç”Ÿæˆå™¨<br/>TemperatureGenerator]
        HUMID_GEN[æ¹¿åº¦ç”Ÿæˆå™¨<br/>HumidityGenerator]
        PRESS_GEN[å‹åŠ›ç”Ÿæˆå™¨<br/>PressureGenerator]
        SWITCH_GEN[å¼€å…³ç”Ÿæˆå™¨<br/>SwitchGenerator]
        CURRENT_GEN[ç”µæµç”Ÿæˆå™¨<br/>CurrentGenerator]
    end
    
    subgraph "æ¨¡æ‹Ÿå¼•æ“å±‚"
        SIM_ENGINE[æ¨¡æ‹Ÿå¼•æ“<br/>SimulationEngine]
        TREND_ENGINE[è¶‹åŠ¿å¼•æ“<br/>TrendEngine]
        ANOMALY_ENGINE[å¼‚å¸¸å¼•æ“<br/>AnomalyEngine]
    end
    
    subgraph "å¹¶å‘æ§åˆ¶å±‚"
        GOROUTINE_POOL[åç¨‹æ± <br/>GoroutinePool]
        RATE_LIMITER[é€Ÿç‡é™åˆ¶å™¨<br/>RateLimiter]
        SYNC_MANAGER[åŒæ­¥ç®¡ç†å™¨<br/>SyncManager]
    end
    
    DEV_MGR --> DEV_FACTORY
    DEV_FACTORY --> DEV_REGISTRY
    
    DEV_REGISTRY --> TEMP_GEN
    DEV_REGISTRY --> HUMID_GEN
    DEV_REGISTRY --> PRESS_GEN
    DEV_REGISTRY --> SWITCH_GEN
    DEV_REGISTRY --> CURRENT_GEN
    
    TEMP_GEN --> SIM_ENGINE
    HUMID_GEN --> SIM_ENGINE
    PRESS_GEN --> SIM_ENGINE
    SWITCH_GEN --> SIM_ENGINE
    CURRENT_GEN --> SIM_ENGINE
    
    SIM_ENGINE --> TREND_ENGINE
    TREND_ENGINE --> ANOMALY_ENGINE
    
    ANOMALY_ENGINE --> GOROUTINE_POOL
    GOROUTINE_POOL --> RATE_LIMITER
    RATE_LIMITER --> SYNC_MANAGER
```

### Kafkaç”Ÿäº§è€…æ¶æ„å›¾
```mermaid
graph TB
    subgraph "ç”Ÿäº§è€…æ ¸å¿ƒå±‚"
        PRODUCER[Kafkaç”Ÿäº§è€…<br/>SaramaProducer]
        CONFIG_MGR[é…ç½®ç®¡ç†å™¨<br/>ConfigManager]
        CONN_POOL[è¿æ¥æ± <br/>ConnectionPool]
    end
    
    subgraph "æ¶ˆæ¯å¤„ç†å±‚"
        MSG_BUILDER[æ¶ˆæ¯æ„å»ºå™¨<br/>MessageBuilder]
        SERIALIZER[åºåˆ—åŒ–å™¨<br/>JSONSerializer]
        COMPRESSOR[å‹ç¼©å™¨<br/>GzipCompressor]
    end
    
    subgraph "åˆ†åŒºè·¯ç”±å±‚"
        PARTITIONER[åˆ†åŒºå™¨<br/>DevicePartitioner]
        LOAD_BALANCER[è´Ÿè½½å‡è¡¡å™¨<br/>LoadBalancer]
        RETRY_MGR[é‡è¯•ç®¡ç†å™¨<br/>RetryManager]
    end
    
    subgraph "æ‰¹é‡å¤„ç†å±‚"
        BATCH_COLLECTOR[æ‰¹é‡æ”¶é›†å™¨<br/>BatchCollector]
        FLUSH_SCHEDULER[åˆ·æ–°è°ƒåº¦å™¨<br/>FlushScheduler]
        BUFFER_MGR[ç¼“å†²ç®¡ç†å™¨<br/>BufferManager]
    end
    
    subgraph "ç›‘æ§æŒ‡æ ‡å±‚"
        METRICS_COLLECTOR[æŒ‡æ ‡æ”¶é›†å™¨<br/>MetricsCollector]
        HEALTH_CHECKER[å¥åº·æ£€æŸ¥å™¨<br/>HealthChecker]
        PERF_MONITOR[æ€§èƒ½ç›‘æ§å™¨<br/>PerformanceMonitor]
    end
    
    PRODUCER --> CONFIG_MGR
    CONFIG_MGR --> CONN_POOL
    
    PRODUCER --> MSG_BUILDER
    MSG_BUILDER --> SERIALIZER
    SERIALIZER --> COMPRESSOR
    
    COMPRESSOR --> PARTITIONER
    PARTITIONER --> LOAD_BALANCER
    LOAD_BALANCER --> RETRY_MGR
    
    RETRY_MGR --> BATCH_COLLECTOR
    BATCH_COLLECTOR --> FLUSH_SCHEDULER
    FLUSH_SCHEDULER --> BUFFER_MGR
    
    BUFFER_MGR --> METRICS_COLLECTOR
    METRICS_COLLECTOR --> HEALTH_CHECKER
    HEALTH_CHECKER --> PERF_MONITOR
```

### æ•°æ®ç”Ÿæˆæµæ°´çº¿æ¶æ„å›¾
```mermaid
flowchart LR
    subgraph "è®¾å¤‡å±‚"
        A[è®¾å¤‡1<br/>æ¸©åº¦ä¼ æ„Ÿå™¨]
        B[è®¾å¤‡2<br/>æ¹¿åº¦ä¼ æ„Ÿå™¨]
        C[è®¾å¤‡N<br/>å¤šä¼ æ„Ÿå™¨]
    end
    
    subgraph "æ•°æ®ç”Ÿæˆå±‚"
        D[æ•°æ®ç”Ÿæˆå™¨<br/>DataGenerator]
        E[è¶‹åŠ¿æ¨¡æ‹Ÿå™¨<br/>TrendSimulator]
        F[å¼‚å¸¸æ³¨å…¥å™¨<br/>AnomalyInjector]
    end
    
    subgraph "åºåˆ—åŒ–å±‚"
        G[JSONåºåˆ—åŒ–å™¨<br/>JSONSerializer]
        H[æ¶ˆæ¯å°è£…å™¨<br/>MessageWrapper]
        I[å‹ç¼©å¤„ç†å™¨<br/>Compressor]
    end
    
    subgraph "Kafkaå‘é€å±‚"
        J[åˆ†åŒºè·¯ç”±å™¨<br/>Partitioner]
        K[æ‰¹é‡å‘é€å™¨<br/>BatchSender]
        L[Kafkaé›†ç¾¤<br/>KafkaCluster]
    end
    
    subgraph "ç›‘æ§å±‚"
        M[TPSç›‘æ§<br/>TPSMonitor]
        N[å»¶è¿Ÿç›‘æ§<br/>LatencyMonitor]
        O[é”™è¯¯ç›‘æ§<br/>ErrorMonitor]
    end
    
    A --> D
    B --> D
    C --> D
    
    D --> E
    E --> F
    
    F --> G
    G --> H
    H --> I
    
    I --> J
    J --> K
    K --> L
    
    K --> M
    K --> N
    K --> O
```

### å¹¶å‘æ§åˆ¶æœºåˆ¶æ¶æ„å›¾
```mermaid
graph TB
    subgraph "ä¸»æ§åˆ¶å™¨"
        MAIN_CTRL[ä¸»æ§åˆ¶å™¨<br/>MainController]
        TASK_SCHEDULER[ä»»åŠ¡è°ƒåº¦å™¨<br/>TaskScheduler]
        RESOURCE_MGR[èµ„æºç®¡ç†å™¨<br/>ResourceManager]
    end
    
    subgraph "åç¨‹æ± ç®¡ç†"
        POOL_MGR[åç¨‹æ± ç®¡ç†å™¨<br/>PoolManager]
        WORKER_POOL[å·¥ä½œåç¨‹æ± <br/>WorkerPool]
        TASK_QUEUE[ä»»åŠ¡é˜Ÿåˆ—<br/>TaskQueue]
    end
    
    subgraph "åŒæ­¥æ§åˆ¶"
        MUTEX_MGR[äº’æ–¥é”ç®¡ç†å™¨<br/>MutexManager]
        CHAN_MGR[é€šé“ç®¡ç†å™¨<br/>ChannelManager]
        WAIT_GROUP[ç­‰å¾…ç»„<br/>WaitGroup]
    end
    
    subgraph "é™æµæ§åˆ¶"
        RATE_LIMITER[é€Ÿç‡é™åˆ¶å™¨<br/>RateLimiter]
        TOKEN_BUCKET[ä»¤ç‰Œæ¡¶<br/>TokenBucket]
        CIRCUIT_BREAKER[ç†”æ–­å™¨<br/>CircuitBreaker]
    end
    
    subgraph "ç›‘æ§åé¦ˆ"
        PERF_MONITOR[æ€§èƒ½ç›‘æ§<br/>PerformanceMonitor]
        LOAD_DETECTOR[è´Ÿè½½æ£€æµ‹å™¨<br/>LoadDetector]
        AUTO_SCALER[è‡ªåŠ¨æ‰©ç¼©å®¹<br/>AutoScaler]
    end
    
    MAIN_CTRL --> TASK_SCHEDULER
    TASK_SCHEDULER --> RESOURCE_MGR
    
    RESOURCE_MGR --> POOL_MGR
    POOL_MGR --> WORKER_POOL
    WORKER_POOL --> TASK_QUEUE
    
    TASK_QUEUE --> MUTEX_MGR
    MUTEX_MGR --> CHAN_MGR
    CHAN_MGR --> WAIT_GROUP
    
    WAIT_GROUP --> RATE_LIMITER
    RATE_LIMITER --> TOKEN_BUCKET
    TOKEN_BUCKET --> CIRCUIT_BREAKER
    
    CIRCUIT_BREAKER --> PERF_MONITOR
    PERF_MONITOR --> LOAD_DETECTOR
    LOAD_DETECTOR --> AUTO_SCALER
    
    AUTO_SCALER --> RESOURCE_MGR
```

## ğŸ“‹ è¯¦ç»†å¼€å‘è®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€è®¾æ–½æ­å»ºï¼ˆç¬¬1-2å¤©ï¼‰

**ç›®æ ‡ï¼š** å»ºç«‹Kafkaç”Ÿäº§è€…åŸºç¡€æ¡†æ¶å’Œè®¾å¤‡æ¨¡æ‹Ÿå™¨æ ¸å¿ƒ

**æ ¸å¿ƒä»»åŠ¡ï¼š**

1. **Kafkaå®¢æˆ·ç«¯åˆå§‹åŒ–**
   - é›†æˆSarama Kafkaå®¢æˆ·ç«¯åº“
   - é…ç½®Kafkaè¿æ¥å‚æ•°å’Œè®¤è¯
   - å®ç°è¿æ¥æ± å’Œå¥åº·æ£€æŸ¥æœºåˆ¶
   - è®¾ç½®ç”Ÿäº§è€…é…ç½®ä¼˜åŒ–å‚æ•°

2. **è®¾å¤‡æ•°æ®æ¨¡æ‹Ÿå™¨æ¡†æ¶**
   - åˆ›å»ºè®¾å¤‡ç®¡ç†å™¨å’Œè®¾å¤‡å·¥å‚
   - å®ç°å¤šç§ä¼ æ„Ÿå™¨ç±»å‹çš„æ•°æ®ç”Ÿæˆå™¨
   - å»ºç«‹è®¾å¤‡æ³¨å†Œè¡¨å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†
   - è®¾è®¡å¯æ‰©å±•çš„ä¼ æ„Ÿå™¨æ¥å£

3. **åŸºç¡€é…ç½®ç³»ç»Ÿ**
   - æ‰©å±•ç°æœ‰é…ç½®ç³»ç»Ÿæ”¯æŒKafkaé…ç½®
   - æ·»åŠ è®¾å¤‡æ¨¡æ‹Ÿå‚æ•°é…ç½®
   - å®ç°ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶æ”¯æŒ
   - å»ºç«‹é…ç½®éªŒè¯å’Œçƒ­é‡è½½æœºåˆ¶

**æŠ€æœ¯è§„æ ¼ï¼š**
```go
// Kafkaç”Ÿäº§è€…é…ç½®
type KafkaProducerConfig struct {
    Brokers          []string      `yaml:"brokers" validate:"required,min=1"`
    Topic            string        `yaml:"topic" validate:"required"`
    ClientID         string        `yaml:"client_id" validate:"required"`
    BatchSize        int           `yaml:"batch_size" validate:"min=1,max=1000000"`
    BatchTimeout     time.Duration `yaml:"batch_timeout" validate:"min=1ms"`
    CompressionType  string        `yaml:"compression" validate:"oneof=none gzip snappy lz4 zstd"`
    MaxRetries       int           `yaml:"max_retries" validate:"min=0,max=10"`
    RetryBackoff     time.Duration `yaml:"retry_backoff" validate:"min=1ms"`
    RequiredAcks     int           `yaml:"required_acks" validate:"oneof=-1 0 1"`
    FlushFrequency   time.Duration `yaml:"flush_frequency" validate:"min=1ms"`
    ChannelBufferSize int          `yaml:"channel_buffer_size" validate:"min=1"`
}

// è®¾å¤‡æ¨¡æ‹Ÿé…ç½®
type DeviceSimulationConfig struct {
    DeviceCount      int           `yaml:"device_count" validate:"min=1,max=100000"`
    SampleInterval   time.Duration `yaml:"sample_interval" validate:"min=100ms"`
    DataVariation    float64       `yaml:"data_variation" validate:"min=0,max=1"`
    AnomalyRate      float64       `yaml:"anomaly_rate" validate:"min=0,max=0.1"`
    TrendEnabled     bool          `yaml:"trend_enabled"`
    TrendStrength    float64       `yaml:"trend_strength" validate:"min=0,max=1"`
    WorkerPoolSize   int           `yaml:"worker_pool_size" validate:"min=1,max=1000"`
    QueueBufferSize  int           `yaml:"queue_buffer_size" validate:"min=100"`
}
```

### ç¬¬äºŒé˜¶æ®µï¼šæ ¸å¿ƒåŠŸèƒ½å®ç°ï¼ˆç¬¬3-4å¤©ï¼‰

**ç›®æ ‡ï¼š** å®ç°é«˜æ€§èƒ½çš„æ•°æ®ç”Ÿæˆå’ŒKafkaæ¶ˆæ¯å‘é€

**æ ¸å¿ƒä»»åŠ¡ï¼š**

1. **æ™ºèƒ½æ•°æ®ç”Ÿæˆç®—æ³•**
   - å®ç°åŸºäºæ­£æ€åˆ†å¸ƒçš„çœŸå®ä¼ æ„Ÿå™¨æ•°æ®æ¨¡æ‹Ÿ
   - æ·»åŠ æ—¶é—´åºåˆ—è¶‹åŠ¿å’Œå­£èŠ‚æ€§å˜åŒ–
   - é›†æˆå¼‚å¸¸æ•°æ®æ³¨å…¥æœºåˆ¶
   - æ”¯æŒå¤šç§ä¼ æ„Ÿå™¨ç±»å‹çš„ä¸“ç”¨ç®—æ³•

2. **é«˜æ€§èƒ½æ¶ˆæ¯ç”Ÿäº§**
   - å®ç°æ‰¹é‡æ¶ˆæ¯æ”¶é›†å’Œå‘é€
   - ä¼˜åŒ–æ¶ˆæ¯åºåˆ—åŒ–å’Œå‹ç¼©
   - å»ºç«‹æ™ºèƒ½åˆ†åŒºç­–ç•¥
   - å®ç°æ¶ˆæ¯é‡è¯•å’Œé”™è¯¯å¤„ç†

3. **å¹¶å‘æ§åˆ¶ç³»ç»Ÿ**
   - è®¾è®¡åç¨‹æ± ç®¡ç†å™¨
   - å®ç°ä»»åŠ¡é˜Ÿåˆ—å’Œè´Ÿè½½å‡è¡¡
   - æ·»åŠ èƒŒå‹æ§åˆ¶å’Œæµé‡æ•´å½¢
   - å»ºç«‹èµ„æºç›‘æ§å’Œè‡ªé€‚åº”è°ƒèŠ‚

**å…³é”®ç®—æ³•å®ç°ï¼š**
```go
// æ™ºèƒ½ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆå™¨
type SensorDataGenerator struct {
    sensorType    string
    baseValue     float64
    variance      float64
    trendFactor   float64
    anomalyRate   float64
    lastValue     float64
    trendDirection int
    random        *rand.Rand
}

func (g *SensorDataGenerator) GenerateValue() float64 {
    // åŸºç¡€æ­£æ€åˆ†å¸ƒå€¼
    normalValue := g.random.NormFloat64() * g.variance + g.baseValue
    
    // æ·»åŠ è¶‹åŠ¿å› å­
    trendValue := normalValue + (g.trendFactor * float64(g.trendDirection))
    
    // å¼‚å¸¸æ³¨å…¥
    if g.random.Float64() < g.anomalyRate {
        anomalyMultiplier := 2.0 + g.random.Float64() * 3.0
        trendValue *= anomalyMultiplier
    }
    
    // å¹³æ»‘è¿‡æ¸¡
    smoothedValue := g.lastValue*0.7 + trendValue*0.3
    g.lastValue = smoothedValue
    
    return smoothedValue
}
```

### ç¬¬ä¸‰é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ–å’Œç›‘æ§ï¼ˆç¬¬5å¤©ï¼‰

**ç›®æ ‡ï¼š** å®ç°ä¼ä¸šçº§æ€§èƒ½å’Œå®Œæ•´ç›‘æ§ä½“ç³»

**æ ¸å¿ƒä»»åŠ¡ï¼š**

1. **æ€§èƒ½ä¼˜åŒ–**
   - å®ç°é›¶æ‹·è´æ¶ˆæ¯ä¼ è¾“
   - ä¼˜åŒ–å†…å­˜åˆ†é…å’Œåƒåœ¾å›æ”¶
   - æ·»åŠ è¿æ¥æ± å’Œèµ„æºå¤ç”¨
   - å®ç°æ™ºèƒ½æ‰¹å¤„ç†ç­–ç•¥

2. **ç›‘æ§æŒ‡æ ‡ç³»ç»Ÿ**
   - é›†æˆPrometheusæŒ‡æ ‡æ”¶é›†
   - å®ç°å®æ—¶æ€§èƒ½ä»ªè¡¨æ¿
   - æ·»åŠ å‘Šè­¦å’Œé€šçŸ¥æœºåˆ¶
   - å»ºç«‹æ€§èƒ½åŸºå‡†æµ‹è¯•

3. **å¯é æ€§ä¿éšœ**
   - å®ç°ä¼˜é›…å…³é—­å’Œèµ„æºæ¸…ç†
   - æ·»åŠ æ•…éšœæ¢å¤å’Œè‡ªæ„ˆæœºåˆ¶
   - å»ºç«‹å¥åº·æ£€æŸ¥å’ŒæœåŠ¡å‘ç°
   - å®ç°é…ç½®çƒ­æ›´æ–°

**ç›‘æ§æŒ‡æ ‡å®šä¹‰ï¼š**
```go
// å…³é”®æ€§èƒ½æŒ‡æ ‡
type KafkaProducerMetrics struct {
    // ååé‡æŒ‡æ ‡
    MessagesPerSecond    prometheus.Counter
    BytesPerSecond       prometheus.Counter
    BatchesPerSecond     prometheus.Counter
    
    // å»¶è¿ŸæŒ‡æ ‡
    SendLatency          prometheus.Histogram
    SerializationLatency prometheus.Histogram
    CompressionLatency   prometheus.Histogram
    
    // é”™è¯¯æŒ‡æ ‡
    SendErrors           prometheus.Counter
    RetryAttempts        prometheus.Counter
    DroppedMessages      prometheus.Counter
    
    // èµ„æºä½¿ç”¨æŒ‡æ ‡
    GoroutineCount       prometheus.Gauge
    MemoryUsage          prometheus.Gauge
    CPUUsage             prometheus.Gauge
    
    // ä¸šåŠ¡æŒ‡æ ‡
    DeviceCount          prometheus.Gauge
    ActiveConnections    prometheus.Gauge
    QueueDepth           prometheus.Gauge
}
```

### ç¬¬å››é˜¶æ®µï¼šé›†æˆæµ‹è¯•å’Œæ–‡æ¡£ï¼ˆç¬¬6å¤©ï¼‰

**ç›®æ ‡ï¼š** å®Œæˆå…¨é¢æµ‹è¯•å’ŒæŠ€æœ¯æ–‡æ¡£

**æ ¸å¿ƒä»»åŠ¡ï¼š**

1. **å…¨é¢æµ‹è¯•è¦†ç›–**
   - å•å…ƒæµ‹è¯•è¦†ç›–ç‡è¾¾åˆ°90%+
   - é›†æˆæµ‹è¯•éªŒè¯ç«¯åˆ°ç«¯æµç¨‹
   - æ€§èƒ½æµ‹è¯•å’Œå‹åŠ›æµ‹è¯•
   - æ•…éšœæ³¨å…¥å’Œæ¢å¤æµ‹è¯•

2. **æŠ€æœ¯æ–‡æ¡£å®Œå–„**
   - APIæ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—
   - æ¶æ„è®¾è®¡å’Œå†³ç­–è®°å½•
   - è¿ç»´æ‰‹å†Œå’Œæ•…éšœæ’æŸ¥
   - æ€§èƒ½è°ƒä¼˜æŒ‡å—

3. **éƒ¨ç½²å‡†å¤‡**
   - Dockerå®¹å™¨åŒ–é…ç½®
   - Kuberneteséƒ¨ç½²æ¸…å•
   - ç›‘æ§å’Œæ—¥å¿—é…ç½®
   - CI/CDæµæ°´çº¿è®¾ç½®

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

### Kafkaç”Ÿäº§è€…æ ¸å¿ƒå®ç°

```go
package producer

import (
    "context"
    "encoding/json"
    "fmt"
    "sync"
    "time"
    
    "github.com/Shopify/sarama"
    "github.com/prometheus/client_golang/prometheus"
)

// KafkaProducer Kafkaç”Ÿäº§è€…å®ç°
type KafkaProducer struct {
    producer     sarama.AsyncProducer
    config       *KafkaProducerConfig
    metrics      *KafkaProducerMetrics
    batchBuffer  chan *sarama.ProducerMessage
    errorChan    chan *sarama.ProducerError
    successChan  chan *sarama.ProducerMessage
    wg           sync.WaitGroup
    ctx          context.Context
    cancel       context.CancelFunc
    isRunning    bool
    mutex        sync.RWMutex
}

// NewKafkaProducer åˆ›å»ºæ–°çš„Kafkaç”Ÿäº§è€…
func NewKafkaProducer(config *KafkaProducerConfig) (*KafkaProducer, error) {
    saramaConfig := sarama.NewConfig()
    saramaConfig.Producer.Return.Successes = true
    saramaConfig.Producer.Return.Errors = true
    saramaConfig.Producer.RequiredAcks = sarama.RequiredAcks(config.RequiredAcks)
    saramaConfig.Producer.Retry.Max = config.MaxRetries
    saramaConfig.Producer.Retry.Backoff = config.RetryBackoff
    saramaConfig.Producer.Flush.Frequency = config.FlushFrequency
    saramaConfig.Producer.Flush.Messages = config.BatchSize
    
    // è®¾ç½®å‹ç¼©ç±»å‹
    switch config.CompressionType {
    case "gzip":
        saramaConfig.Producer.Compression = sarama.CompressionGZIP
    case "snappy":
        saramaConfig.Producer.Compression = sarama.CompressionSnappy
    case "lz4":
        saramaConfig.Producer.Compression = sarama.CompressionLZ4
    case "zstd":
        saramaConfig.Producer.Compression = sarama.CompressionZSTD
    default:
        saramaConfig.Producer.Compression = sarama.CompressionNone
    }
    
    producer, err := sarama.NewAsyncProducer(config.Brokers, saramaConfig)
    if err != nil {
        return nil, fmt.Errorf("failed to create Kafka producer: %w", err)
    }
    
    ctx, cancel := context.WithCancel(context.Background())
    
    kp := &KafkaProducer{
        producer:    producer,
        config:      config,
        metrics:     NewKafkaProducerMetrics(),
        batchBuffer: make(chan *sarama.ProducerMessage, config.ChannelBufferSize),
        errorChan:   make(chan *sarama.ProducerError, 100),
        successChan: make(chan *sarama.ProducerMessage, 100),
        ctx:         ctx,
        cancel:      cancel,
        isRunning:   false,
    }
    
    return kp, nil
}

// Start å¯åŠ¨ç”Ÿäº§è€…
func (kp *KafkaProducer) Start() error {
    kp.mutex.Lock()
    defer kp.mutex.Unlock()
    
    if kp.isRunning {
        return fmt.Errorf("producer is already running")
    }
    
    kp.isRunning = true
    
    // å¯åŠ¨æ¶ˆæ¯å¤„ç†åç¨‹
    kp.wg.Add(3)
    go kp.handleSuccesses()
    go kp.handleErrors()
    go kp.batchProcessor()
    
    return nil
}

// SendMessage å‘é€æ¶ˆæ¯
func (kp *KafkaProducer) SendMessage(key string, value interface{}) error {
    if !kp.isRunning {
        return fmt.Errorf("producer is not running")
    }
    
    // åºåˆ—åŒ–æ¶ˆæ¯
    valueBytes, err := json.Marshal(value)
    if err != nil {
        kp.metrics.SendErrors.Inc()
        return fmt.Errorf("failed to marshal message: %w", err)
    }
    
    message := &sarama.ProducerMessage{
        Topic:     kp.config.Topic,
        Key:       sarama.StringEncoder(key),
        Value:     sarama.ByteEncoder(valueBytes),
        Timestamp: time.Now(),
    }
    
    select {
    case kp.batchBuffer <- message:
        return nil
    case <-kp.ctx.Done():
        return fmt.Errorf("producer is shutting down")
    default:
        kp.metrics.DroppedMessages.Inc()
        return fmt.Errorf("message buffer is full")
    }
}

// batchProcessor æ‰¹é‡å¤„ç†æ¶ˆæ¯
func (kp *KafkaProducer) batchProcessor() {
    defer kp.wg.Done()
    
    ticker := time.NewTicker(kp.config.BatchTimeout)
    defer ticker.Stop()
    
    batch := make([]*sarama.ProducerMessage, 0, kp.config.BatchSize)
    
    for {
        select {
        case message := <-kp.batchBuffer:
            batch = append(batch, message)
            
            if len(batch) >= kp.config.BatchSize {
                kp.sendBatch(batch)
                batch = batch[:0] // é‡ç½®åˆ‡ç‰‡
            }
            
        case <-ticker.C:
            if len(batch) > 0 {
                kp.sendBatch(batch)
                batch = batch[:0]
            }
            
        case <-kp.ctx.Done():
            // å‘é€å‰©ä½™æ¶ˆæ¯
            if len(batch) > 0 {
                kp.sendBatch(batch)
            }
            return
        }
    }
}

// sendBatch å‘é€æ‰¹é‡æ¶ˆæ¯
func (kp *KafkaProducer) sendBatch(batch []*sarama.ProducerMessage) {
    start := time.Now()
    
    for _, message := range batch {
        select {
        case kp.producer.Input() <- message:
            kp.metrics.MessagesPerSecond.Inc()
        case <-kp.ctx.Done():
            return
        }
    }
    
    kp.metrics.BatchesPerSecond.Inc()
    kp.metrics.SendLatency.Observe(time.Since(start).Seconds())
}

// handleSuccesses å¤„ç†æˆåŠŸæ¶ˆæ¯
func (kp *KafkaProducer) handleSuccesses() {
    defer kp.wg.Done()
    
    for {
        select {
        case success := <-kp.producer.Successes():
            kp.metrics.BytesPerSecond.Add(float64(len(success.Value.(sarama.ByteEncoder))))
            
        case <-kp.ctx.Done():
            return
        }
    }
}

// handleErrors å¤„ç†é”™è¯¯æ¶ˆæ¯
func (kp *KafkaProducer) handleErrors() {
    defer kp.wg.Done()
    
    for {
        select {
        case err := <-kp.producer.Errors():
            kp.metrics.SendErrors.Inc()
            // è¿™é‡Œå¯ä»¥æ·»åŠ é”™è¯¯æ—¥å¿—è®°å½•
            fmt.Printf("Kafka producer error: %v\n", err)
            
        case <-kp.ctx.Done():
            return
        }
    }
}

// Stop åœæ­¢ç”Ÿäº§è€…
func (kp *KafkaProducer) Stop() error {
    kp.mutex.Lock()
    defer kp.mutex.Unlock()
    
    if !kp.isRunning {
        return nil
    }
    
    kp.cancel()
    kp.wg.Wait()
    
    if err := kp.producer.Close(); err != nil {
        return fmt.Errorf("failed to close producer: %w", err)
    }
    
    kp.isRunning = false
    return nil
}
```

## ğŸ“ˆ æ€§èƒ½ç›®æ ‡å’ŒæŒ‡æ ‡

### å…³é”®æ€§èƒ½æŒ‡æ ‡ (KPIs)

| æŒ‡æ ‡ç±»åˆ« | æŒ‡æ ‡åç§° | ç›®æ ‡å€¼ | ç›‘æ§æ–¹å¼ |
|----------|----------|----------|----------|
| **ååé‡** | æ¶ˆæ¯/ç§’ | 10,000+ | Prometheus Counter |
| **ååé‡** | å­—èŠ‚/ç§’ | 10MB+ | Prometheus Counter |
| **å»¶è¿Ÿ** | å‘é€å»¶è¿Ÿ | <10ms | Prometheus Histogram |
| **å¯é æ€§** | æˆåŠŸç‡ | >99.9% | Prometheus Counter |
| **èµ„æº** | CPUä½¿ç”¨ç‡ | <80% | Prometheus Gauge |
| **èµ„æº** | å†…å­˜ä½¿ç”¨ | <2GB | Prometheus Gauge |

### ç›‘æ§ä»ªè¡¨æ¿è®¾è®¡

```yaml
# Grafanaä»ªè¡¨æ¿é…ç½®
dashboard:
  title: "Industrial IoT Kafka Producer Monitoring"
  panels:
    - title: "ååé‡æŒ‡æ ‡"
      type: "graph"
      metrics:
        - "kafka_producer_messages_per_second"
        - "kafka_producer_bytes_per_second"
    
    - title: "å»¶è¿Ÿåˆ†å¸ƒ"
      type: "heatmap"
      metrics:
        - "kafka_producer_send_latency_histogram"
    
    - title: "é”™è¯¯ç‡ç›‘æ§"
      type: "singlestat"
      metrics:
        - "kafka_producer_error_rate"
```

## ğŸš€ éƒ¨ç½²å’Œé›†æˆ

### Dockerå®¹å™¨åŒ–

```dockerfile
# Dockerfile
FROM golang:1.21-alpine AS builder
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o kafka-producer ./cmd/producer

FROM alpine:latest
RUN apk --no-cache add ca-certificates tzdata
WORKDIR /root/
COPY --from=builder /app/kafka-producer .
COPY --from=builder /app/configs ./configs
EXPOSE 8080 9090
CMD ["./kafka-producer"]
```

### Kuberneteséƒ¨ç½²æ¸…å•

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-producer
  namespace: iot-monitoring
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kafka-producer
  template:
    metadata:
      labels:
        app: kafka-producer
    spec:
      containers:
      - name: kafka-producer
        image: iot-monitoring/kafka-producer:latest
        ports:
        - containerPort: 8080
        - containerPort: 9090
        env:
        - name: KAFKA_BROKERS
          value: "kafka-cluster:9092"
        - name: KAFKA_TOPIC
          value: "iot-sensor-data"
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"
```

## ğŸ“š æŠ€æœ¯æ–‡æ¡£å’Œæœ€ä½³å®è·µ

### é…ç½®æœ€ä½³å®è·µ

1. **ç”Ÿäº§ç¯å¢ƒé…ç½®**
   - æ‰¹å¤§å°: 500-1000æ¶ˆæ¯
   - æ‰¹è¶…æ—¶: 10-50ms
   - å‹ç¼©: GZIPæˆ–Snappy
   - é‡è¯•æ¬¡æ•°: 3-5æ¬¡

2. **æ€§èƒ½è°ƒä¼˜æŒ‡å—**
   - æ ¹æ®ç½‘ç»œå¸¦å®½è°ƒæ•´æ‰¹å¤§å°
   - ç›‘æ§é˜Ÿåˆ—æ·±åº¦é¿å…èƒŒå‹
   - åˆç†è®¾ç½®åç¨‹æ± å¤§å°
   - å®šæœŸæ¸…ç†è¿‡æœŸè¿æ¥

3. **ç›‘æ§å‘Šè­¦è®¾ç½®**
   - é”™è¯¯ç‡ > 1%æ—¶å‘Šè­¦
   - å»¶è¿Ÿ > 100msæ—¶å‘Šè­¦
   - å†…å­˜ä½¿ç”¨ > 80%æ—¶å‘Šè­¦
   - é˜Ÿåˆ—æ·±åº¦ > 1000æ—¶å‘Šè­¦

### æ•…éšœæ’æŸ¥æŒ‡å—

1. **å¸¸è§é—®é¢˜è¯Šæ–­**
   - è¿æ¥è¶…æ—¶: æ£€æŸ¥ç½‘ç»œå’ŒKafkaé›†ç¾¤çŠ¶æ€
   - æ¶ˆæ¯ä¸¢å¤±: æ£€æŸ¥acksé…ç½®å’Œé‡è¯•æœºåˆ¶
   - å†…å­˜æ³„æ¼: æ£€æŸ¥åç¨‹å’Œè¿æ¥æ± ç®¡ç†
   - æ€§èƒ½ä¸‹é™: æ£€æŸ¥æ‰¹å¤„ç†å’Œå‹ç¼©é…ç½®

2. **æ—¥å¿—åˆ†æ**
   - å¯ç”¨è¯¦ç»†æ—¥å¿—è®°å½•å…³é”®æ“ä½œ
   - ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—ä¾¿äºåˆ†æ
   - è®¾ç½®æ—¥å¿—è½®è½¬é¿å…ç£ç›˜å æ»¡
   - é›†æˆELKæ ˆè¿›è¡Œæ—¥å¿—èšåˆ

## ğŸ¯ é¡¹ç›®æˆæœå±•ç¤º

### GitHubä½œå“é›†äº®ç‚¹

1. **ä¼ä¸šçº§Kafkaç”Ÿäº§è€…å®ç°**
   - é«˜æ€§èƒ½å¼‚æ­¥æ¶ˆæ¯å‘é€
   - æ™ºèƒ½æ‰¹å¤„ç†å’Œå‹ç¼©
   - å®Œæ•´çš„ç›‘æ§å’Œå‘Šè­¦ä½“ç³»
   - ç”Ÿäº§çº§é”™è¯¯å¤„ç†å’Œæ¢å¤

2. **å·¥ä¸šIoTæ•°æ®æ¨¡æ‹Ÿ**
   - çœŸå®ä¼ æ„Ÿå™¨æ•°æ®ç®—æ³•
   - å¤šè®¾å¤‡å¹¶å‘æ¨¡æ‹Ÿ
   - å¼‚å¸¸æ•°æ®æ³¨å…¥æœºåˆ¶
   - å¯é…ç½®çš„æ•°æ®ç”Ÿæˆç­–ç•¥

3. **æŠ€æœ¯æ¶æ„è®¾è®¡**
   - æ¸…æ™°çš„æ¨¡å—åŒ–è®¾è®¡
   - å®Œæ•´çš„æ¶æ„æ–‡æ¡£
   - è¯¦ç»†çš„æ€§èƒ½åŸºå‡†æµ‹è¯•
   - ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ–¹æ¡ˆ

### æŠ€æœ¯æ¼”ç¤ºè¦ç‚¹

- **é«˜å¹¶å‘å¤„ç†**: æ”¯æŒ10,000+ TPSçš„æ¶ˆæ¯å‘é€
- **æ™ºèƒ½ä¼˜åŒ–**: è‡ªé€‚åº”æ‰¹å¤„ç†å’ŒèƒŒå‹æ§åˆ¶
- **ç›‘æ§å®Œæ•´**: Prometheus + Grafanaç›‘æ§ä½“ç³»
- **éƒ¨ç½²å‹å¥½**: Docker + Kubernetesäº‘åŸç”Ÿéƒ¨ç½²
- **æ–‡æ¡£å®Œå–„**: è¯¦ç»†çš„APIæ–‡æ¡£å’Œè¿ç»´æŒ‡å—

---

*æœ¬æ–‡æ¡£ä¸ºStep 2.1 Kafkaç”Ÿäº§è€…å®ç°çš„å®Œæ•´æŠ€æœ¯è§„èŒƒï¼Œä¸ºåç»­çš„æ¶ˆè´¹è€…é›†æˆ(Step 2.2)å’ŒWebSocketæœåŠ¡(Step 3.1)æä¾›äº†åšå®çš„åŸºç¡€ã€‚*
